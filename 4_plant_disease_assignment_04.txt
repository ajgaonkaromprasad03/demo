assignment_04

import kagglehub
import os
import matplotlib.pyplot as plt
from PIL import Image
import yaml
import tensorflow as tf
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns





# Download dataset
path = kagglehub.dataset_download("farukalam/tomato-leaf-diseases-detection-computer-vision")
print("Path to dataset files:", path)

# Define dataset path
dataset_path = path
print(f"Dataset path: {dataset_path}")

# Configuration
IMG_HEIGHT = 224
IMG_WIDTH = 224
BATCH_SIZE = 32
TRAIN_SPLIT = 0.7
VAL_SPLIT = 0.15
TEST_SPLIT = 0.15
EPOCHS = 5  # Low epochs for quick training

print(f"\nConfiguration:")
print(f"Image size: {IMG_HEIGHT}x{IMG_WIDTH}")
print(f"Batch size: {BATCH_SIZE}")
print(f"Epochs: {EPOCHS}")
print(f"Splits - Train: {TRAIN_SPLIT}, Val: {VAL_SPLIT}, Test: {TEST_SPLIT}")

# Parse data.yaml for class names
data_yaml_path = os.path.join(dataset_path, 'data.yaml')
with open(data_yaml_path, 'r') as f:
    data_yaml = yaml.safe_load(f)
true_class_names = data_yaml.get('names', [])
num_classes = len(true_class_names)

print(f"\nDisease categories ({num_classes}):")
for class_name in true_class_names:
    print(f"- {class_name}")

# Collect images and labels
train_dir = os.path.join(dataset_path, 'train')
train_img_dir = os.path.join(train_dir, 'images')
train_label_dir = os.path.join(train_dir, 'labels')

images_by_class = {name: [] for name in true_class_names}
all_image_files = [f for f in os.listdir(train_img_dir) 
                   if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]

print(f"\nProcessing {len(all_image_files)} images...")

for img_file in all_image_files:
    base_name = os.path.splitext(img_file)[0]
    label_file_name = base_name + '.txt'
    label_path = os.path.join(train_label_dir, label_file_name)
    
    if os.path.exists(label_path):
        with open(label_path, 'r') as f:
            labels = f.readlines()
        
        if labels:
            first_label_line = labels[0].strip()
            parts = first_label_line.split()
            if parts and parts[0].isdigit():
                class_idx = int(parts[0])
                if 0 <= class_idx < len(true_class_names):
                    class_name = true_class_names[class_idx]
                    images_by_class[class_name].append(os.path.join(train_img_dir, img_file))




# Count images per class
print("\nImages per class:")
for class_name in true_class_names:
    count = len(images_by_class[class_name])
    print(f"- {class_name}: {count} images")

# Prepare data
all_image_paths = []
all_image_labels = []
for class_name, image_paths_list in images_by_class.items():
    class_idx = true_class_names.index(class_name)
    for img_path in image_paths_list:
        all_image_paths.append(img_path)
        all_image_labels.append(class_idx)

print(f"\nTotal images: {len(all_image_paths)}")

# Convert to numpy arrays
all_image_paths_np = np.array(all_image_paths)
all_image_labels_np = np.array(all_image_labels)

# Split data
num_samples = len(all_image_paths_np)
num_train = int(TRAIN_SPLIT * num_samples)
num_val = int(VAL_SPLIT * num_samples)
num_test = num_samples - num_train - num_val

X_temp, X_test, y_temp, y_test = train_test_split(
    all_image_paths_np, all_image_labels_np, 
    test_size=num_test, random_state=42, stratify=all_image_labels_np
)

val_split_from_temp = num_val / len(X_temp)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, 
    test_size=val_split_from_temp, random_state=42, stratify=y_temp
)

print(f"\nDataset splits:")
print(f"Training samples: {len(X_train)}")
print(f"Validation samples: {len(X_val)}")
print(f"Test samples: {len(X_test)}")

# Preprocessing function
def preprocess_image(image_path, label):
    img = tf.io.read_file(image_path)
    img = tf.image.decode_image(img, channels=3, expand_animations=False)
    img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])
    img = tf.cast(img, tf.float32) / 255.0
    return img, label

AUTOTUNE = tf.data.AUTOTUNE

# Create datasets
train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))
val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))
test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))

train_ds = train_ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)
val_ds = val_ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)
test_ds = test_ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)

# Data augmentation (simple)
data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal"),
    tf.keras.layers.RandomRotation(0.1),
], name="data_augmentation")

def augment_train_data(image, label):
    image = data_augmentation(image)
    return image, label

train_ds = train_ds.map(augment_train_data, num_parallel_calls=AUTOTUNE)
train_ds = train_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)
val_ds = val_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)
test_ds = test_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)

print("\nDatasets prepared and batched")



# Build model
base_model = tf.keras.applications.MobileNetV2(
    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),
    include_top=False,
    weights='imagenet'
)
base_model.trainable = False  # Freeze base model for faster training

model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(num_classes, activation='softmax')
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)

print("\nModel built and compiled")
model.summary()

# Callbacks
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True,
    verbose=1
)

model_checkpoint = tf.keras.callbacks.ModelCheckpoint(
    'best_model_weights.weights.h5',
    monitor='val_loss',
    save_best_only=True,
    save_weights_only=True,
    verbose=1
)

# Train model
print("\n" + "="*50)
print("Starting training...")
print("="*50)

history = model.fit(
    train_ds,
    epochs=EPOCHS,
    validation_data=val_ds,
    callbacks=[early_stopping, model_checkpoint]
)

print("\nTraining completed!")

# Plot training history
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

# Load best weights and evaluate
model.load_weights('best_model_weights.weights.h5')
print("\nBest model weights loaded")

test_loss, test_accuracy = model.evaluate(test_ds)
print(f"\nTest Results:")
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

# Get predictions
predictions = model.predict(test_ds)
predicted_labels = np.argmax(predictions, axis=1)
true_labels = np.concatenate([y for x, y in test_ds], axis=0)






# Classification report
print("\nClassification Report:")
print(classification_report(true_labels, predicted_labels, target_names=true_class_names))

# Confusion matrix
conf_matrix = confusion_matrix(true_labels, predicted_labels)
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', 
            xticklabels=true_class_names, yticklabels=true_class_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

# Display sample predictions
test_images = []
test_labels_raw = []
for images_batch, labels_batch in test_ds.unbatch().take(100).as_numpy_iterator():
    test_images.append(images_batch)
    test_labels_raw.append(labels_batch)

test_images_np = np.array(test_images)
test_labels_np = np.array(test_labels_raw)

num_display_samples = 10
random_indices = np.random.choice(len(test_images_np), 
                                 min(num_display_samples, len(test_images_np)), 
                                 replace=False)

plt.figure(figsize=(15, 8))
for i, idx in enumerate(random_indices):
    image = test_images_np[idx]
    true_label_idx = test_labels_np[idx]
    predicted_label_idx = predicted_labels[idx]
    true_label_name = true_class_names[true_label_idx]
    predicted_label_name = true_class_names[predicted_label_idx]
    
    plt.subplot(2, 5, i + 1)
    plt.imshow(image)
    color = "green" if true_label_idx == predicted_label_idx else "red"
    title_text = f"True: {true_label_name}\nPred: {predicted_label_name}"
    plt.title(title_text, color=color, fontsize=9)
    plt.axis('off')

plt.tight_layout()
plt.show()

print("\nâœ… Training and evaluation complete!")










                    